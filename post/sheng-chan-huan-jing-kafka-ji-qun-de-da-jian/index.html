<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>生产环境kafka集群的搭建 | Gridea</title>
<link rel="shortcut icon" href="https://moruikang.github.io/favicon.ico?v=1766469477645">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://moruikang.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="生产环境kafka集群的搭建 | Gridea - Atom Feed" href="https://moruikang.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="一.kafka介绍
Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。
特点

顺序读写磁盘，高吞吐量
本地持久化消息
分布式消息系统
..." />
    <meta name="keywords" content="kafka" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="//cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.5.1/build/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://moruikang.github.io">
  <img class="avatar" src="https://moruikang.github.io/images/avatar.png?v=1766469477645" alt="">
  </a>
  <h1 class="site-title">
    Gridea
  </h1>
  <p class="site-description">
    日常成长提炼
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              生产环境kafka集群的搭建
            </h2>
            <div class="post-info">
              <span>
                2020-01-01
              </span>
              <span>
                10 min read
              </span>
              
                <a href="https://moruikang.github.io/tag/IH8U1DdCfu/" class="post-tag">
                  # kafka
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content" v-pre>
                <h2 id="一kafka介绍">一.kafka介绍</h2>
<p>Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。</p>
<h3 id="特点">特点</h3>
<ul>
<li>顺序读写磁盘，高吞吐量</li>
<li>本地持久化消息</li>
<li>分布式消息系统</li>
</ul>
<h3 id="架构">架构</h3>
<p><img src="https://moruikang.github.io/post-images/1739881268313.png" alt="" loading="lazy"><br>
Kafka架构的主要术语包括Producer、 Consumer、Topic、Partition和Broker。</p>
<p>Producer: 负责发布消息到Kafka broker<br>
Consumer、ConsumerGroup: Consumer是消息消费者，向Kafka broker读取消息的客户端，每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）<br>
Topic: 用来对消息进行分类，每个进入到Kafka的信息都会被放到一个Topic下<br>
Partition: 每个Topic中的消息会被分为一个或多个Partition<br>
<img src="https://moruikang.github.io/post-images/1739881313834.webp" alt="" loading="lazy"><br>
Broker: 用来实现数据存储的主机服务器<br>
Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic；向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份kafka消息。</p>
<h2 id="二部署">二.部署</h2>
<h3 id="1部署服务器节点">1.部署服务器节点</h3>
<figure data-type="image" tabindex="1"><img src="https://moruikang.github.io/post-images/1739881359823.jpg" alt="" loading="lazy"></figure>
<h4 id="服务器环境">服务器环境</h4>
<table>
<thead>
<tr>
<th style="text-align:center">节点</th>
<th style="text-align:center">IP</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">node1</td>
<td style="text-align:center">192.168.2.43</td>
</tr>
<tr>
<td style="text-align:center">node2</td>
<td style="text-align:center">192.168.2.44</td>
</tr>
<tr>
<td style="text-align:center">node3</td>
<td style="text-align:center">192.168.2.45</td>
</tr>
</tbody>
</table>
<h4 id="系统和依赖">系统和依赖：</h4>
<ul>
<li>ubuntu 18.04</li>
<li>java openjdk version &quot;1.8.0_222&quot; (自行安装)</li>
</ul>
<h3 id="2安装zookeeper">2.安装zookeeper</h3>
<p>node1,node2,node3都要下载和安装<br>
下载版本： https://archive.apache.org/dist/zookeeper/zookeeper-3.4.12/</p>
<pre><code>$ cd /opt
$ wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.12/zookeeper-3.4.12.tar.gz
$ tar -zxvf  zookeeper-3.4.12.tar.gz
$ cd zookeeper-3.4.12
</code></pre>
<p>修改配置：</p>
<pre><code>$ vim conf/zoo.cfg 
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/zookeeper-3.4.12/data    ###根据实际情况修改
dataLogDir=/opt/zookeeper-3.4.12/log  ###根据实际情况修改
clientPort=2181
server.1=192.168.2.43:2888:3888
server.2=192.168.2.44:2888:3888
server.3=192.168.2.45:2888:3888

#server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里
#192.168.2.43-45为集群里的IP地址，第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行重新选举的端口，默认是3888
</code></pre>
<h4 id="21-配置文件解释">2.1 配置文件解释：</h4>
<p>#tickTime：<br>
这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每间隔 tickTime时间就会发送一个心跳。<br>
#initLimit：<br>
这个配置项是用来配置Zookeeper接受客户端（这里所说的客户端不是用户连接Zookeeper服务器的客户端，而是Zookeeper服务器集群中连接到Leader的Follower服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过5个心跳的时间（也就是tickTime）长度后，Zookeeper服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度等于52000=10秒<br>
#syncLimit：<br>
这个配置项标识Leader与Follower之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime的时间长度，总的时间长度就是52000=10秒<br>
#dataDir：<br>
快照日志的存储路径<br>
#dataLogDir：<br>
事务日志的存储路径，如果不配置这个，那么事务日志会默认存储到dataDir指定的目录，这会严重影响zk的性能，当zk吞吐量较大的时候，产生的事务日志、快照日志会很多。<br>
#clientPort：<br>
客户端连接Zookeeper服务器的端口，Zookeeper监听这个端口，接受客户端的访问请求。</p>
<pre><code>#node1
$ echo &quot;1&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
#node2
$ echo &quot;2&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
#node3
$ echo &quot;3&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
</code></pre>
<p>创建zookerper.service的systemd系统守护进程<br>
node1,node2,node3都需要操作</p>
<pre><code>$ tee zookeeper.service &gt; /dev/null &lt;&lt;EOF
[Unit]
Description=ZooKeeper Service
Documentation=http://zookeeper.apache.org
Requires=network.target
After=network.target
[Service]
Type=forking
User=ubuntu
Group=ubuntu
ExecStart=/opt/zookeeper-3.4.12/bin/zkServer.sh start 
ExecStop=/opt/zookeeper-3.4.12/bin/zkServer.sh stop 
ExecReload=/opt/zookeeper-3.4.12/bin/zkServer.sh restart
WorkingDirectory=/var/log/zookeeper
EOF
$ cp zookeeper.service  /etc/systemd/system/zookeeper.service
$ systemctl enable zookeeper.service
$ systemctl start zookeeper.service 
$ systemctl status zookeeper.service 
</code></pre>
<pre><code>#进入到Zookeeper的bin目录下 （3台都需要操作）
$ cd /opt/zookeeper-3.4.12/bin
#检查服务状态 
$ ./zkServer.sh status
</code></pre>
<h3 id="3-安装kafka">3. 安装kafka</h3>
<h4 id="31-创建目录并下载安装软件">3.1 创建目录并下载安装软件</h4>
<h5 id="安装目录">安装目录</h5>
<pre><code>$ cd /opt
#下载软件
$ wget http://mirror.bit.edu.cn/apache/kafka/2.1.1/kafka_2.11-2.1.1.tgz #解压软件
$ tar -zxvf kafka_2.11-2.1.1.tgz
</code></pre>
<h4 id="32-修改配置文件">3.2 修改配置文件</h4>
<p>进入到config目录</p>
<pre><code>$ cd /opt/kafka_2.11-2.1.1/config
$ vim server.properties   
broker.id=0 #当前机器在集群中的唯一标识，和zookeeper的myid性质一样，建议node1为0，node2为1，node3为2
listeners=PLAINTEXT://192.168.2.43:9092 #kafka监听地址，根据本机ip填写
num.network.threads=5 # borker进行网络处理的线程数,建议不大于CPU的2倍
num.io.threads=10  # borker进行I/O处理的线程数
socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后再发送，能提高性能
socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后再序列化到磁盘
socket.request.max.bytes=104857600 #向kafka请求消息或者向kafka发送消息的最大请求数，这个值不能超过java的堆栈大小
log.dirs=/data/kafka-logs #消息存放的目录，多个目录使用&quot;,&quot;逗号分割，上面num.io.threads要大于目录的个数；如果配置多个目录，新创建的topic把消息持久化在当前目录列表中分区数最少的那个目录。
num.partitions=6 #默认的分区数，默认1个分区数
num.recovery.threads.per.data.dir=1
log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
log.segment.bytes=1073741824 #kafka的消息是以追加的形式存储到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息，如果有，删除
offsets.topic.replication.factor=3 #kafka会把offset信息存在这个topic里面，当是集群部署时，这个副本数等于节点数
zookeeper.connect=192.168.2.43:2181,192.168.2.44:2181,192.168.2.45:2181#设置zookeeper的连接端口
message.max.byte=5242880
default.replication.factor=3
replica.fetch.max.bytes=5242880
zookeeper.connection.timeout.ms=6000 #连接zookeeper的超时时间 
auto.leader.rebalance.enable=true
</code></pre>
<p>创建zookerper.service的systemd系统守护进程<br>
node1,node2,node3都需要操作</p>
<pre><code>$ tee kafkals.service &gt; /dev/null &lt;&lt;EOF
[Unit]
Description=Apache Kafka server (broker)
Documentation=http://kafka.apache.org/documentation.html
Requires=network.target remote-fs.target
After=network.target remote-fs.target zookeeper.service
[Service]
Type=simple
User=ubuntu
Group=ubuntu
ExecStart=/opt/kafka_2.11-2.1.1/bin/kafka-server-start.sh /opt/kafka_2.11-2.1.1/config/server.properties
ExecStop=/opt/kafka_2.11-2.1.1/bin/kafka-server-stop.sh
WorkingDirectory=/var/log/kafka
[Install]
WantedBy=multi-user.target
EOF
$ cp kafka.service  /etc/systemd/system/kafka.service
$ systemctl enable kafka.service
$ systemctl start kafka.service 
$ systemctl status kafka.service 
</code></pre>
<h4 id="33-创建topic来验证是否创建成功">3.3 创建Topic来验证是否创建成功</h4>
<pre><code>#创建Topic
$ cd /opt/kafka_2.11-2.1.1/bin
$ kafka-topics.sh --create --zookeeper 192.168.2.43:2181 --replication-factor 3 --partitions 6 --topic test
#解释 --replication-factor 3 复制两份; --partitions 6 创建6个分区; --topic 主题为test 
#在一台服务器上创建发布者
$ kafka-console-producer.sh --broker-list 192.168.2.43:9092 --topic test   ###从这里输入发送的消息 
</code></pre>
<pre><code>#新开一个终端，创建一个消费者，接收消息
kafka-console-consumer.sh --zookeeper 192.168.2.43:2181 --topic test --from-beginning
</code></pre>
<p>上面的完成之后可以登录zk来查看zk的目录情况</p>
<pre><code>#使用客户端进入
cd /opt/zookeeper-3.4.12/bin ./zkCli.sh 
#查看目录情况 执行
[zk: 192.168.2.43:2181(CONNECTED) 1] ls /  #查看目录
[zk: 192.168.2.43:2181(CONNECTED) 1] get /brokers/ids/0 #查看broker
</code></pre>
<h4 id="34-日志说明">3.4 日志说明</h4>
<p>默认kafka的日志保存在/opt/kafka/kafka_2.12-0.10.2.1/logs目录下，这里说几个需要注意的日志</p>
<p>server.log #kafka的运行日志<br>
state-change.log #kafka用zookeeper来保存状态，有可能会进行切换，切换的日志就保存在这里<br>
controller.log #kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在可用分区的所有节点中选择新的leader,这使得Kafka可以批量高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会被切换为新的controller.</p>
<h3 id="三-建议">三. 建议</h3>
<ul>
<li>kafka和zookeeper分开部署在单独节点，CPU选择IO优化，给足够的带宽</li>
<li>kafka是IO类型，建议挂多块磁盘给不同partition</li>
<li>partition分区数根据消费者来定</li>
<li>根据需求修改zookeeper和kafka jvm参数</li>
<li>做好kafka监控，特别关注lag指标</li>
</ul>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80kafka%E4%BB%8B%E7%BB%8D">一.kafka介绍</a>
<ul>
<li><a href="#%E7%89%B9%E7%82%B9">特点</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84">架构</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E9%83%A8%E7%BD%B2">二.部署</a>
<ul>
<li><a href="#1%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8A%82%E7%82%B9">1.部署服务器节点</a>
<ul>
<li><a href="#%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%8E%AF%E5%A2%83">服务器环境</a></li>
<li><a href="#%E7%B3%BB%E7%BB%9F%E5%92%8C%E4%BE%9D%E8%B5%96">系统和依赖：</a></li>
</ul>
</li>
<li><a href="#2%E5%AE%89%E8%A3%85zookeeper">2.安装zookeeper</a>
<ul>
<li><a href="#21-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E9%87%8A">2.1 配置文件解释：</a></li>
</ul>
</li>
<li><a href="#3-%E5%AE%89%E8%A3%85kafka">3. 安装kafka</a>
<ul>
<li><a href="#31-%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%E5%B9%B6%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6">3.1 创建目录并下载安装软件</a>
<ul>
<li><a href="#%E5%AE%89%E8%A3%85%E7%9B%AE%E5%BD%95">安装目录</a></li>
</ul>
</li>
<li><a href="#32-%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">3.2 修改配置文件</a></li>
<li><a href="#33-%E5%88%9B%E5%BB%BAtopic%E6%9D%A5%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E5%88%9B%E5%BB%BA%E6%88%90%E5%8A%9F">3.3 创建Topic来验证是否创建成功</a></li>
<li><a href="#34-%E6%97%A5%E5%BF%97%E8%AF%B4%E6%98%8E">3.4 日志说明</a></li>
</ul>
</li>
<li><a href="#%E4%B8%89-%E5%BB%BA%E8%AE%AE">三. 建议</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
  <a class="rss" href="https://moruikang.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
