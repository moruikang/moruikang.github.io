<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>生产环境kafka集群的搭建 | moruikang&#39; blog</title>
<meta name="description" content="温故而知新" />
<link rel="shortcut icon" href="https://moruikang.github.io/favicon.ico?v=1579081407601">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
<link rel="stylesheet" href="https://moruikang.github.io/styles/main.css">

<script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://moruikang.github.io">
  <img class="avatar" src="https://moruikang.github.io/images/avatar.png?v=1579081407601" alt="">
  </a>
  <h1 class="site-title">
    moruikang&#39; blog
  </h1>
  <p class="site-description">
    温故而知新
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              生产环境kafka集群的搭建
            </h2>
            <div class="post-info">
              <span>
                2020-01-01
              </span>
              <span>
                10 min read
              </span>
              
                <a href="https://moruikang.github.io/tag/u5orQEpN4" class="post-tag">
                  # kafka
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <h2 id="一kafka介绍">一.kafka介绍</h2>
<h4 id="kafka是由apache软件基金会开发的一个开源流处理平台由scala和java编写-该项目的目标是为处理实时数据提供一个统一-高吞吐-低延迟的平台">Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。</h4>
<h3 id="特点">特点</h3>
<ul>
<li>顺序读写磁盘，高吞吐量</li>
<li>本地持久化消息</li>
<li>分布式消息系统</li>
</ul>
<h3 id="架构">架构</h3>
<p><img src="https://moruikang.github.io/post-images/1577710975402.png" alt=""><br>
Kafka架构的主要术语包括Producer、 Consumer、Topic、Partition和Broker。</p>
<ul>
<li>Producer: 负责发布消息到Kafka broker</li>
<li>Consumer、ConsumerGroup: Consumer是消息消费者，向Kafka broker读取消息的客户端，每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）</li>
<li>Topic: 用来对消息进行分类，每个进入到Kafka的信息都会被放到一个Topic下</li>
<li>Partition: 每个Topic中的消息会被分为一个或多个Partition<br>
<img src="https://moruikang.github.io/post-images/1577711957585.webp" alt=""></li>
<li>Broker: 用来实现数据存储的主机服务器</li>
</ul>
<p>Kafka中发布订阅的对象是topic。我们可以为每类数据创建一个topic；向topic发布消息的客户端称作producer，从topic订阅消息的客户端称作consumer。Producers和consumers可以同时从多个topic读写数据。一个kafka集群由一个或多个broker服务器组成，它负责持久化和备份kafka消息。</p>
<h2 id="二部署">二.部署</h2>
<h3 id="1部署服务器节点">1.部署服务器节点</h3>
<p><img src="https://moruikang.github.io/post-images/1577712041184.jpg" alt=""><br>
服务器环境</p>
<table>
<thead>
<tr>
<th style="text-align:left">节点</th>
<th style="text-align:right">ip</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">node3</td>
<td style="text-align:right">192.168.2.43</td>
</tr>
<tr>
<td style="text-align:left">node2</td>
<td style="text-align:right">192.168.2.44</td>
</tr>
<tr>
<td style="text-align:left">node3</td>
<td style="text-align:right">192.168.2.45</td>
</tr>
</tbody>
</table>
<p>系统和依赖：</p>
<ul>
<li>ubuntu 18.04</li>
<li>java openjdk version &quot;1.8.0_222&quot; (自行安装)</li>
</ul>
<h3 id="2安装zookeeper">2.安装zookeeper</h3>
<p>node1,node2,node3都要下载和安装<br>
下载版本： https://archive.apache.org/dist/zookeeper/zookeeper-3.4.12/</p>
<pre><code>$ cd /opt
$ wget https://archive.apache.org/dist/zookeeper/zookeeper-3.4.12/zookeeper-3.4.12.tar.gz
$ tar -zxvf  zookeeper-3.4.12.tar.gz
$ cd zookeeper-3.4.12
修改配置：
$ vim conf/zoo.cfg 
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/opt/zookeeper-3.4.12/data    ###根据实际情况修改
dataLogDir=/opt/zookeeper-3.4.12/log  ###根据实际情况修改
clientPort=2181
server.1=192.168.2.43:2888:3888
server.2=192.168.2.44:2888:3888
server.3=192.168.2.45:2888:3888
#server.1 这个1是服务器的标识也可以是其他的数字， 表示这个是第几号服务器，用来标识服务器，这个标识要写到快照目录下面myid文件里
#192.168.2.43-45为集群里的IP地址，第一个端口是master和slave之间的通信端口，默认是2888，第二个端口是leader选举的端口，集群刚启动的时候选举或者leader挂掉之后进行重新选举的端口，默认是3888
</code></pre>
<h4 id="21-配置文件解释">2.1 配置文件解释：</h4>
<p>#tickTime：<br>
这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每间隔 tickTime时间就会发送一个心跳。<br>
#initLimit：<br>
这个配置项是用来配置Zookeeper接受客户端（这里所说的客户端不是用户连接Zookeeper服务器的客户端，而是Zookeeper服务器集群中连接到Leader的Follower服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过5个心跳的时间（也就是tickTime）长度后，Zookeeper服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度等于5<em>2000=10秒<br>
#syncLimit：<br>
这个配置项标识Leader与Follower之间发送消息，请求和应答时间长度，最长不能超过多少个tickTime的时间长度，总的时间长度就是5</em>2000=10秒<br>
#dataDir：<br>
快照日志的存储路径<br>
#dataLogDir：<br>
事务日志的存储路径，如果不配置这个，那么事务日志会默认存储到dataDir指定的目录，这会严重影响zk的性能，当zk吞吐量较大的时候，产生的事务日志、快照日志会很多。<br>
#clientPort：<br>
客户端连接Zookeeper服务器的端口，Zookeeper监听这个端口，接受客户端的访问请求。</p>
<pre><code>#node1
$ echo &quot;1&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
#node2
$ echo &quot;2&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
#node3
$ echo &quot;3&quot; &gt; /opt/zookeeper-3.4.12/data/myid 
</code></pre>
<p>创建zookerper.service的systemd系统守护进程<br>
node1,node2,node3都需要操作</p>
<pre><code>$ tee zookeeper.service &gt; /dev/null &lt;&lt;EOF
[Unit]
Description=ZooKeeper Service
Documentation=http://zookeeper.apache.org
Requires=network.target
After=network.target
[Service]
Type=forking
User=ubuntu
Group=ubuntu
ExecStart=/opt/zookeeper-3.4.12/bin/zkServer.sh start 
ExecStop=/opt/zookeeper-3.4.12/bin/zkServer.sh stop 
ExecReload=/opt/zookeeper-3.4.12/bin/zkServer.sh restart
WorkingDirectory=/var/log/zookeeper
EOF
$ cp zookeeper.service  /etc/systemd/system/zookeeper.service
$ systemctl enable zookeeper.service
$ systemctl start zookeeper.service 
$ systemctl status zookeeper.service 
</code></pre>
<pre><code>#进入到Zookeeper的bin目录下 （3台都需要操作）
$ cd /opt/zookeeper-3.4.12/bin
#检查服务状态 
$ ./zkServer.sh status
</code></pre>
<h3 id="3-安装kafka">3. 安装kafka</h3>
<h4 id="31-创建目录并下载安装软件">3.1 创建目录并下载安装软件</h4>
<p>#安装目录</p>
<pre><code>$ cd /opt
#下载软件
$ wget http://mirror.bit.edu.cn/apache/kafka/2.1.1/kafka_2.11-2.1.1.tgz #解压软件
$ tar -zxvf kafka_2.11-2.1.1.tgz
</code></pre>
<h4 id="32-修改配置文件">3.2 修改配置文件</h4>
<p>进入到config目录</p>
<pre><code>$ cd /opt/kafka_2.11-2.1.1/config
$ vim server.properties   
broker.id=0 #当前机器在集群中的唯一标识，和zookeeper的myid性质一样，建议node1为0，node2为1，node3为2
listeners=PLAINTEXT://192.168.2.43:9092 #kafka监听地址，根据本机ip填写
num.network.threads=5 # borker进行网络处理的线程数,建议不大于CPU的2倍
num.io.threads=10  # borker进行I/O处理的线程数
socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后再发送，能提高性能
socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后再序列化到磁盘
socket.request.max.bytes=104857600 #向kafka请求消息或者向kafka发送消息的最大请求数，这个值不能超过java的堆栈大小
log.dirs=/data/kafka-logs #消息存放的目录，多个目录使用&quot;,&quot;逗号分割，上面num.io.threads要大于目录的个数；如果配置多个目录，新创建的topic把消息持久化在当前目录列表中分区数最少的那个目录。
num.partitions=6 #默认的分区数，默认1个分区数
num.recovery.threads.per.data.dir=1
log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
log.segment.bytes=1073741824 #kafka的消息是以追加的形式存储到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息，如果有，删除
offsets.topic.replication.factor=3 #kafka会把offset信息存在这个topic里面，当是集群部署时，这个副本数等于节点数
zookeeper.connect=192.168.2.43:2181,192.168.2.44:2181,192.168.2.45:2181#设置zookeeper的连接端口
message.max.byte=5242880
default.replication.factor=3
replica.fetch.max.bytes=5242880
zookeeper.connection.timeout.ms=6000 #连接zookeeper的超时时间 
auto.leader.rebalance.enable=true
</code></pre>
<p>创建zookerper.service的systemd系统守护进程<br>
node1,node2,node3都需要操作</p>
<pre><code>$ tee kafkals.service &gt; /dev/null &lt;&lt;EOF
[Unit]
Description=Apache Kafka server (broker)
Documentation=http://kafka.apache.org/documentation.html
Requires=network.target remote-fs.target
After=network.target remote-fs.target zookeeper.service
[Service]
Type=simple
User=ubuntu
Group=ubuntu
ExecStart=/opt/kafka_2.11-2.1.1/bin/kafka-server-start.sh /opt/kafka_2.11-2.1.1/config/server.properties
ExecStop=/opt/kafka_2.11-2.1.1/bin/kafka-server-stop.sh
WorkingDirectory=/var/log/kafka
[Install]
WantedBy=multi-user.target
EOF
$ cp kafka.service  /etc/systemd/system/kafka.service
$ systemctl enable kafka.service
$ systemctl start kafka.service 
$ systemctl status kafka.service 
</code></pre>
<h4 id="33-创建topic来验证是否创建成功">3.3 创建Topic来验证是否创建成功</h4>
<pre><code>#创建Topic
$ cd /opt/kafka_2.11-2.1.1/bin
$ kafka-topics.sh --create --zookeeper 192.168.2.43:2181 --replication-factor 3 --partitions 6 --topic test
#解释 --replication-factor 3 复制两份; --partitions 6 创建6个分区; --topic 主题为test 
#在一台服务器上创建发布者
$ kafka-console-producer.sh --broker-list 192.168.2.43:9092 --topic test   ###从这里输入发送的消息 
</code></pre>
<pre><code>#新开一个终端，创建一个消费者，接收消息
kafka-console-consumer.sh --zookeeper 192.168.2.43:2181 --topic test --from-beginning
</code></pre>
<p>上面的完成之后可以登录zk来查看zk的目录情况</p>
<pre><code>#使用客户端进入
cd /opt/zookeeper-3.4.12/bin ./zkCli.sh 
#查看目录情况 执行
[zk: 192.168.2.43:2181(CONNECTED) 1] ls /  #查看目录
[zk: 192.168.2.43:2181(CONNECTED) 1] get /brokers/ids/0 #查看broker
</code></pre>
<h4 id="34-日志说明">3.4 日志说明</h4>
<p>默认kafka的日志保存在/opt/kafka/kafka_2.12-0.10.2.1/logs目录下，这里说几个需要注意的日志</p>
<p>server.log #kafka的运行日志<br>
state-change.log  #kafka用zookeeper来保存状态，有可能会进行切换，切换的日志就保存在这里<br>
controller.log #kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在可用分区的所有节点中选择新的leader,这使得Kafka可以批量高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会被切换为新的controller.</p>
<h2 id="三-建议">三. 建议</h2>
<h4 id="31-kafka和zookeeper分开部署在单独节点cpu选择io优化给足够的带宽">3.1 kafka和zookeeper分开部署在单独节点，CPU选择IO优化，给足够的带宽</h4>
<h4 id="32-kafka是io类型建议挂多块磁盘给不同partition">3.2 kafka是IO类型，建议挂多块磁盘给不同partition</h4>
<h4 id="33-partition分区数根据消费者来定">3.3 partition分区数根据消费者来定</h4>
<h4 id="34-根据需求修改zookeeper和kafka-jvm参数">3.4 根据需求修改zookeeper和kafka jvm参数</h4>
<h4 id="35-做好kafka监控特别关注lag指标">3.5 做好kafka监控，特别关注lag指标</h4>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E4%B8%80kafka%E4%BB%8B%E7%BB%8D">一.kafka介绍</a><br>
*
<ul>
<li><a href="#kafka%E6%98%AF%E7%94%B1apache%E8%BD%AF%E4%BB%B6%E5%9F%BA%E9%87%91%E4%BC%9A%E5%BC%80%E5%8F%91%E7%9A%84%E4%B8%80%E4%B8%AA%E5%BC%80%E6%BA%90%E6%B5%81%E5%A4%84%E7%90%86%E5%B9%B3%E5%8F%B0%E7%94%B1scala%E5%92%8Cjava%E7%BC%96%E5%86%99-%E8%AF%A5%E9%A1%B9%E7%9B%AE%E7%9A%84%E7%9B%AE%E6%A0%87%E6%98%AF%E4%B8%BA%E5%A4%84%E7%90%86%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E6%8F%90%E4%BE%9B%E4%B8%80%E4%B8%AA%E7%BB%9F%E4%B8%80-%E9%AB%98%E5%90%9E%E5%90%90-%E4%BD%8E%E5%BB%B6%E8%BF%9F%E7%9A%84%E5%B9%B3%E5%8F%B0">Kafka是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。</a></li>
<li><a href="#%E7%89%B9%E7%82%B9">特点</a></li>
<li><a href="#%E6%9E%B6%E6%9E%84">架构</a></li>
</ul>
</li>
<li><a href="#%E4%BA%8C%E9%83%A8%E7%BD%B2">二.部署</a>
<ul>
<li><a href="#1%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%8A%82%E7%82%B9">1.部署服务器节点</a></li>
<li><a href="#2%E5%AE%89%E8%A3%85zookeeper">2.安装zookeeper</a>
<ul>
<li><a href="#21-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E9%87%8A">2.1 配置文件解释：</a></li>
</ul>
</li>
<li><a href="#3-%E5%AE%89%E8%A3%85kafka">3. 安装kafka</a>
<ul>
<li><a href="#31-%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%E5%B9%B6%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6">3.1 创建目录并下载安装软件</a></li>
<li><a href="#32-%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">3.2 修改配置文件</a></li>
<li><a href="#33-%E5%88%9B%E5%BB%BAtopic%E6%9D%A5%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E5%88%9B%E5%BB%BA%E6%88%90%E5%8A%9F">3.3 创建Topic来验证是否创建成功</a></li>
<li><a href="#34-%E6%97%A5%E5%BF%97%E8%AF%B4%E6%98%8E">3.4 日志说明</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%89-%E5%BB%BA%E8%AE%AE">三. 建议</a><br>
*
<ul>
<li><a href="#31-kafka%E5%92%8Czookeeper%E5%88%86%E5%BC%80%E9%83%A8%E7%BD%B2%E5%9C%A8%E5%8D%95%E7%8B%AC%E8%8A%82%E7%82%B9cpu%E9%80%89%E6%8B%A9io%E4%BC%98%E5%8C%96%E7%BB%99%E8%B6%B3%E5%A4%9F%E7%9A%84%E5%B8%A6%E5%AE%BD">3.1 kafka和zookeeper分开部署在单独节点，CPU选择IO优化，给足够的带宽</a></li>
<li><a href="#32-kafka%E6%98%AFio%E7%B1%BB%E5%9E%8B%E5%BB%BA%E8%AE%AE%E6%8C%82%E5%A4%9A%E5%9D%97%E7%A3%81%E7%9B%98%E7%BB%99%E4%B8%8D%E5%90%8Cpartition">3.2 kafka是IO类型，建议挂多块磁盘给不同partition</a></li>
<li><a href="#33-partition%E5%88%86%E5%8C%BA%E6%95%B0%E6%A0%B9%E6%8D%AE%E6%B6%88%E8%B4%B9%E8%80%85%E6%9D%A5%E5%AE%9A">3.3 partition分区数根据消费者来定</a></li>
<li><a href="#34-%E6%A0%B9%E6%8D%AE%E9%9C%80%E6%B1%82%E4%BF%AE%E6%94%B9zookeeper%E5%92%8Ckafka-jvm%E5%8F%82%E6%95%B0">3.4 根据需求修改zookeeper和kafka jvm参数</a></li>
<li><a href="#35-%E5%81%9A%E5%A5%BDkafka%E7%9B%91%E6%8E%A7%E7%89%B9%E5%88%AB%E5%85%B3%E6%B3%A8lag%E6%8C%87%E6%A0%87">3.5 做好kafka监控，特别关注lag指标</a></li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        

        

        <div class="site-footer">
  Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | 
  <a class="rss" href="https://moruikang.github.io/atom.xml" target="_blank">RSS</a>
</div>

<script>
  hljs.initHighlightingOnLoad()

  let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

  // This should probably be throttled.
  // Especially because it triggers during smooth scrolling.
  // https://lodash.com/docs/4.17.10#throttle
  // You could do like...
  // window.addEventListener("scroll", () => {
  //    _.throttle(doThatStuff, 100);
  // });
  // Only not doing it here to keep this Pen dependency-free.

  window.addEventListener("scroll", event => {
    let fromTop = window.scrollY;

    mainNavLinks.forEach((link, index) => {
      let section = document.getElementById(decodeURI(link.hash).substring(1));
      let nextSection = null
      if (mainNavLinks[index + 1]) {
        nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
      }
      if (section.offsetTop <= fromTop) {
        if (nextSection) {
          if (nextSection.offsetTop > fromTop) {
            link.classList.add("current");
          } else {
            link.classList.remove("current");    
          }
        } else {
          link.classList.add("current");
        }
      } else {
        link.classList.remove("current");
      }
    });
  });

</script>

      </div>
    </div>
  </body>
</html>
